{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing /mnt/Archive/PDB/pdb3noy.ent ...\n"
     ]
    }
   ],
   "source": [
    "from utils.dist_matrix import PDB_Features #parse_pdb, pairwise_distance_matrix\n",
    "\n",
    "pdb_file = '/mnt/Archive/PDB/pdb3noy.ent'\n",
    "\n",
    "pdb_obj = PDB_Features()\n",
    "\n",
    "pdb_obj.parse_pdb(pdb_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['A', 'B', 'C', 'D'])\n"
     ]
    }
   ],
   "source": [
    "print(pdb_obj.b_coords.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.10536041, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cross = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "y = tf.constant([1])\n",
    "y_hat = tf.constant([0.9])\n",
    "\n",
    "print(cross(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.35667494393873245\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.log(0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 6 2], shape=(3,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[1 2]\n",
      "  [1 2]\n",
      "  [1 2]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[1 2]\n",
      "  [1 2]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]], shape=(2, 6, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "const_x = tf.constant([[[1,2],[1,2],[1,2],[1,2],[1,2],[1,2]],[[1,2],[1,2],[1,2],[1,2],[1,2],[1,2]]])\n",
    "print(tf.shape(const_x))\n",
    "const_w = tf.constant([[1,1,1,0,0,0], [1,1,0,0,0,0]])\n",
    "const_w = tf.reshape(const_w, shape=(2,6,1))\n",
    "const_w = tf.repeat(const_w, repeats=2, axis=2)\n",
    "print(tf.math.multiply(const_x,const_w))\n",
    "#t_const = tf.stack(const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 2]), array([1, 3]))\n",
      "(array([1, 3]), array([1, 2]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "z1 = np.array([[1,2],[1,3]])\n",
    "z2 = np.array([[1,3],[1,2]])\n",
    "z = zip(z1,z2)\n",
    "for i in z:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class zip in module builtins:\n",
      "\n",
      "class zip(object)\n",
      " |  zip(*iterables) --> zip object\n",
      " |  \n",
      " |  Return a zip object whose .__next__() method returns a tuple where\n",
      " |  the i-th element comes from the i-th iterable argument.  The .__next__()\n",
      " |  method continues until the shortest iterable in the argument sequence\n",
      " |  is exhausted and then it raises StopIteration.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __next__(self, /)\n",
      " |      Implement next(self).\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Return state information for pickling.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0107068   0.32356328  4.665213    1.5130591  -0.67706996  1.1051533\n",
      "   0.4209537  -0.08746843  0.50248766  0.4810901   0.91254205 -0.5190129\n",
      "  -1.2713071   0.62562406  1.3677851   0.16221178 -0.8852673   0.04397293\n",
      "   1.520272    2.8300133 ]\n",
      " [-0.43514097  4.8007693   0.31030488 -1.0824617   0.64300966 -0.3672495\n",
      "  -0.8494483   0.05788492  0.19099395 -0.52630484  0.49610126 -2.0529504\n",
      "   1.8891007  -0.12361313 -0.556635   -2.107251    0.8517825  -0.343\n",
      "   0.4806744  -1.9603109 ]]\n",
      "[[1.7454512e-02 8.7798061e-03 6.7458951e-01 2.8845396e-02 3.2278653e-03\n",
      "  1.9183386e-02 9.6779000e-03 5.8207121e-03 1.0500038e-02 1.0277749e-02\n",
      "  1.5822506e-02 3.7805834e-03 1.7817289e-03 1.1875952e-02 2.4945069e-02\n",
      "  7.4715549e-03 2.6211783e-03 6.6383546e-03 2.9054204e-02 1.0765207e-01]\n",
      " [4.4752713e-03 8.4090388e-01 9.4311032e-03 2.3425641e-03 1.3153891e-02\n",
      "  4.7896556e-03 2.9572500e-03 7.3271943e-03 8.3704004e-03 4.0853331e-03\n",
      "  1.1356716e-02 8.8759261e-04 4.5732468e-02 6.1110258e-03 3.9632842e-03\n",
      "  8.4068131e-04 1.6207766e-02 4.9072220e-03 1.1182860e-02 9.7374787e-04]]\n",
      "tf.Tensor(\n",
      "[[ 0.7660542   0.31272528  0.9998227   0.9074804  -0.5896113   0.8023425\n",
      "   0.39773357 -0.08724605  0.4640713   0.44711623  0.7223501  -0.4769378\n",
      "  -0.8541515   0.5550317   0.87818646  0.16080385 -0.7090483   0.04394461\n",
      "   0.90874505  0.99305934]\n",
      " [-0.40960872  0.99986476  0.30071443 -0.7941102   0.5669453  -0.3515835\n",
      "  -0.6907812   0.05782036  0.18870495 -0.4825514   0.45904547 -0.9675837\n",
      "   0.9552946  -0.12298735 -0.5054765  -0.97087115  0.69199955 -0.33015302\n",
      "   0.44678354 -0.9611136 ]], shape=(2, 20), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nnorm_I = tfa.layers.InstanceNormalization(beta_initializer=\\'zeros\\' ,gamma_initializer=\"ones\")\\nnorm_B = tf.keras.layers.BatchNormalization(beta_initializer=\\'zeros\\' ,gamma_initializer=\"ones\")\\nnorm_L = tf.keras.layers.LayerNormalization(beta_initializer=\\'zeros\\' ,gamma_initializer=\"ones\")\\nfor i, batch in enumerate(x_train):\\n    print(norm_I(batch[0].numpy()))\\n    print(norm_B(batch[0].numpy()))\\n    print(norm_L(batch[0].numpy()))\\n    break\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from utils import preprocessing as pre\n",
    "\n",
    "dir_ = '/mnt/Archive/Data_Sets/OGT/ogt_classes'\n",
    "\n",
    "names_class = ['ogt_4_15.fasta', 'ogt_26_37.fasta', 'ogt_48_59.fasta', 'ogt_70_81.fasta']\n",
    "names_reg = ['ogt_4_15.fasta', 'ogt_15_26.fasta', 'ogt_26_37.fasta', 'ogt_37_48.fasta', 'ogt_48_59.fasta', 'ogt_59_70.fasta', 'ogt_70_81.fasta']\n",
    "\n",
    "\n",
    "#data_train, data_val = pre.prepare_dataset_reg(dir_, names_reg,seq_length = 512,t_v_split = 0.1,max_samples = 700)\n",
    "\n",
    "#x_train = data_train.shuffle(buffer_size = 7000).batch(64, drop_remainder=True) \n",
    "#x_val = data_val.shuffle(buffer_size = 7000).batch(64, drop_remainder=True)\n",
    "\n",
    "x = tf.constant([[0, 0, 1, 0,0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0],[0, 1, 0, 0,0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0]], dtype=tf.float32)\n",
    "\n",
    "noise = tf.keras.layers.GaussianNoise(1.0)\n",
    "sfm   = tf.keras.layers.Softmax(axis=-1)\n",
    "x = noise(x*5, True)\n",
    "print(x.numpy())\n",
    "print(sfm(x).numpy())\n",
    "print(tf.math.tanh(x))\n",
    "\"\"\"\n",
    "norm_I = tfa.layers.InstanceNormalization(beta_initializer='zeros' ,gamma_initializer=\"ones\")\n",
    "norm_B = tf.keras.layers.BatchNormalization(beta_initializer='zeros' ,gamma_initializer=\"ones\")\n",
    "norm_L = tf.keras.layers.LayerNormalization(beta_initializer='zeros' ,gamma_initializer=\"ones\")\n",
    "for i, batch in enumerate(x_train):\n",
    "    print(norm_I(batch[0].numpy()))\n",
    "    print(norm_B(batch[0].numpy()))\n",
    "    print(norm_L(batch[0].numpy()))\n",
    "    break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sandra/Documents/PHD_projects/Cycle_gan\n",
      "/home/sandra/Documents/PHD_projects\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "currentdir = os.path.dirname(os.getcwd())\n",
    "print(currentdir)\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "print(parentdir)\n",
    "sys.path.append(currentdir)\n",
    "from utils.layers_new import GumbelSoftmax\n",
    "\n",
    "obj = GumbelSoftmax(temperature = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "In[0] and In[1] must have compatible batch dimensions: [2,2,3] vs. [3,2,2] [Op:BatchMatMulV2] name: matmul/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0d98f94b6dd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_mat_mul_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madjoint_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madjoint_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;31m# Neither matmul nor sparse_matmul support adjoint, so we conjugate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul_v2\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1701\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1704\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madj_x\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: In[0] and In[1] must have compatible batch dimensions: [2,2,3] vs. [3,2,2] [Op:BatchMatMulV2] name: matmul/"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#g = -tf.math.log(-tf.math.log(tf.random.uniform(tf.constant([1000,]), minval=0, maxval=1, dtype=tf.dtypes.float32)))\n",
    "\n",
    "sm = tf.keras.layers.Softmax(axis=-1)\n",
    "\n",
    "logit = tf.constant([[[5,4 , 3],[9.9, 10, 9.8]],[[5,4 , 3],[9.9, 10, 9.8]]], dtype=tf.float32)\n",
    "\n",
    "print(logit @ tf.transpose(logit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "currentdir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(currentdir)\n",
    "from utils.losses import  NonReduceingLoss\n",
    "import tensorflow as tf\n",
    "\n",
    "loss = NonReduceingLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22314353 0.06160023]\n"
     ]
    }
   ],
   "source": [
    "logit = tf.constant([[[0.8, 0.1 , 0.1],[0.9, 0.02, 0.098]],[[0.8, 0.1, 0.1],[0.9, 0.1, 0.0]]], dtype=tf.float32)\n",
    "true = tf.constant([[[1, 0 , 0],[1, 0, 0]],[[1, 0, 0],[1, 0, 0]]], dtype=tf.float32)\n",
    "w = tf.constant([[[1],[1]],[[1],[0]]], dtype=tf.float32)\n",
    "print(loss.cycle_loss_fn(true, logit, w).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "file = \"config.yaml\"\n",
    "with open(file, 'r') as file_descriptor:\n",
    "    data = yaml.load(file_descriptor, Loader=yaml.FullLoader)\n",
    "    \n",
    "print(type(data[\"CycleGan\"]['Generator']['filters']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "currentdir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(currentdir) \n",
    "import utils.preprocessing as pre\n",
    "\n",
    "seq = \"abhkcsea\"\n",
    "\n",
    "print(pre.to_binary(seq, max_length=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
