{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing /mnt/Archive/PDB/pdb3noy.ent ...\n"
     ]
    }
   ],
   "source": [
    "from utils.dist_matrix import PDB_Features #parse_pdb, pairwise_distance_matrix\n",
    "\n",
    "pdb_file = '/mnt/Archive/PDB/pdb3noy.ent'\n",
    "\n",
    "pdb_obj = PDB_Features()\n",
    "\n",
    "pdb_obj.parse_pdb(pdb_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['A', 'B', 'C', 'D'])\n"
     ]
    }
   ],
   "source": [
    "print(pdb_obj.b_coords.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.10536041, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cross = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "y = tf.constant([1])\n",
    "y_hat = tf.constant([0.9])\n",
    "\n",
    "print(cross(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.35667494393873245\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.log(0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 6 2], shape=(3,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[1 2]\n",
      "  [1 2]\n",
      "  [1 2]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[1 2]\n",
      "  [1 2]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]], shape=(2, 6, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "const_x = tf.constant([[[1,2],[1,2],[1,2],[1,2],[1,2],[1,2]],[[1,2],[1,2],[1,2],[1,2],[1,2],[1,2]]])\n",
    "print(tf.shape(const_x))\n",
    "const_w = tf.constant([[1,1,1,0,0,0], [1,1,0,0,0,0]])\n",
    "const_w = tf.reshape(const_w, shape=(2,6,1))\n",
    "const_w = tf.repeat(const_w, repeats=2, axis=2)\n",
    "print(tf.math.multiply(const_x,const_w))\n",
    "#t_const = tf.stack(const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 2]), array([1, 3]))\n",
      "(array([1, 3]), array([1, 2]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "z1 = np.array([[1,2],[1,3]])\n",
    "z2 = np.array([[1,3],[1,2]])\n",
    "z = zip(z1,z2)\n",
    "for i in z:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class zip in module builtins:\n",
      "\n",
      "class zip(object)\n",
      " |  zip(*iterables) --> zip object\n",
      " |  \n",
      " |  Return a zip object whose .__next__() method returns a tuple where\n",
      " |  the i-th element comes from the i-th iterable argument.  The .__next__()\n",
      " |  method continues until the shortest iterable in the argument sequence\n",
      " |  is exhausted and then it raises StopIteration.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __next__(self, /)\n",
      " |      Implement next(self).\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Return state information for pickling.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0107068   0.32356328  4.665213    1.5130591  -0.67706996  1.1051533\n",
      "   0.4209537  -0.08746843  0.50248766  0.4810901   0.91254205 -0.5190129\n",
      "  -1.2713071   0.62562406  1.3677851   0.16221178 -0.8852673   0.04397293\n",
      "   1.520272    2.8300133 ]\n",
      " [-0.43514097  4.8007693   0.31030488 -1.0824617   0.64300966 -0.3672495\n",
      "  -0.8494483   0.05788492  0.19099395 -0.52630484  0.49610126 -2.0529504\n",
      "   1.8891007  -0.12361313 -0.556635   -2.107251    0.8517825  -0.343\n",
      "   0.4806744  -1.9603109 ]]\n",
      "[[1.7454512e-02 8.7798061e-03 6.7458951e-01 2.8845396e-02 3.2278653e-03\n",
      "  1.9183386e-02 9.6779000e-03 5.8207121e-03 1.0500038e-02 1.0277749e-02\n",
      "  1.5822506e-02 3.7805834e-03 1.7817289e-03 1.1875952e-02 2.4945069e-02\n",
      "  7.4715549e-03 2.6211783e-03 6.6383546e-03 2.9054204e-02 1.0765207e-01]\n",
      " [4.4752713e-03 8.4090388e-01 9.4311032e-03 2.3425641e-03 1.3153891e-02\n",
      "  4.7896556e-03 2.9572500e-03 7.3271943e-03 8.3704004e-03 4.0853331e-03\n",
      "  1.1356716e-02 8.8759261e-04 4.5732468e-02 6.1110258e-03 3.9632842e-03\n",
      "  8.4068131e-04 1.6207766e-02 4.9072220e-03 1.1182860e-02 9.7374787e-04]]\n",
      "tf.Tensor(\n",
      "[[ 0.7660542   0.31272528  0.9998227   0.9074804  -0.5896113   0.8023425\n",
      "   0.39773357 -0.08724605  0.4640713   0.44711623  0.7223501  -0.4769378\n",
      "  -0.8541515   0.5550317   0.87818646  0.16080385 -0.7090483   0.04394461\n",
      "   0.90874505  0.99305934]\n",
      " [-0.40960872  0.99986476  0.30071443 -0.7941102   0.5669453  -0.3515835\n",
      "  -0.6907812   0.05782036  0.18870495 -0.4825514   0.45904547 -0.9675837\n",
      "   0.9552946  -0.12298735 -0.5054765  -0.97087115  0.69199955 -0.33015302\n",
      "   0.44678354 -0.9611136 ]], shape=(2, 20), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nnorm_I = tfa.layers.InstanceNormalization(beta_initializer=\\'zeros\\' ,gamma_initializer=\"ones\")\\nnorm_B = tf.keras.layers.BatchNormalization(beta_initializer=\\'zeros\\' ,gamma_initializer=\"ones\")\\nnorm_L = tf.keras.layers.LayerNormalization(beta_initializer=\\'zeros\\' ,gamma_initializer=\"ones\")\\nfor i, batch in enumerate(x_train):\\n    print(norm_I(batch[0].numpy()))\\n    print(norm_B(batch[0].numpy()))\\n    print(norm_L(batch[0].numpy()))\\n    break\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from utils import preprocessing as pre\n",
    "\n",
    "dir_ = '/mnt/Archive/Data_Sets/OGT/ogt_classes'\n",
    "\n",
    "names_class = ['ogt_4_15.fasta', 'ogt_26_37.fasta', 'ogt_48_59.fasta', 'ogt_70_81.fasta']\n",
    "names_reg = ['ogt_4_15.fasta', 'ogt_15_26.fasta', 'ogt_26_37.fasta', 'ogt_37_48.fasta', 'ogt_48_59.fasta', 'ogt_59_70.fasta', 'ogt_70_81.fasta']\n",
    "\n",
    "\n",
    "#data_train, data_val = pre.prepare_dataset_reg(dir_, names_reg,seq_length = 512,t_v_split = 0.1,max_samples = 700)\n",
    "\n",
    "#x_train = data_train.shuffle(buffer_size = 7000).batch(64, drop_remainder=True) \n",
    "#x_val = data_val.shuffle(buffer_size = 7000).batch(64, drop_remainder=True)\n",
    "\n",
    "x = tf.constant([[0, 0, 1, 0,0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0],[0, 1, 0, 0,0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0]], dtype=tf.float32)\n",
    "\n",
    "noise = tf.keras.layers.GaussianNoise(1.0)\n",
    "sfm   = tf.keras.layers.Softmax(axis=-1)\n",
    "x = noise(x*5, True)\n",
    "print(x.numpy())\n",
    "print(sfm(x).numpy())\n",
    "print(tf.math.tanh(x))\n",
    "\"\"\"\n",
    "norm_I = tfa.layers.InstanceNormalization(beta_initializer='zeros' ,gamma_initializer=\"ones\")\n",
    "norm_B = tf.keras.layers.BatchNormalization(beta_initializer='zeros' ,gamma_initializer=\"ones\")\n",
    "norm_L = tf.keras.layers.LayerNormalization(beta_initializer='zeros' ,gamma_initializer=\"ones\")\n",
    "for i, batch in enumerate(x_train):\n",
    "    print(norm_I(batch[0].numpy()))\n",
    "    print(norm_B(batch[0].numpy()))\n",
    "    print(norm_L(batch[0].numpy()))\n",
    "    break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sandra/Documents/PHD_projects/Cycle_gan\n",
      "/home/sandra/Documents/PHD_projects\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "currentdir = os.path.dirname(os.getcwd())\n",
    "print(currentdir)\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "print(parentdir)\n",
    "sys.path.append(currentdir)\n",
    "from utils.layers_new import GumbelSoftmax\n",
    "\n",
    "obj = GumbelSoftmax(temperature = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 5.   4.   3. ]\n",
      " [ 9.9 10.   9.8]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.66524094 0.24472848 0.09003057]\n",
      " [0.3322249  0.36716542 0.30060968]], shape=(2, 3), dtype=float32)\n",
      "[[9.9999547e-01 4.5321272e-06 3.6660929e-08]\n",
      " [9.0746337e-01 2.4019338e-02 6.8517320e-02]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#g = -tf.math.log(-tf.math.log(tf.random.uniform(tf.constant([1000,]), minval=0, maxval=1, dtype=tf.dtypes.float32)))\n",
    "\n",
    "sm = tf.keras.layers.Softmax(axis=-1)\n",
    "\n",
    "logit = tf.constant([[5,4 , 3],[9.9, 10, 9.8]], dtype=tf.float32)\n",
    "p = sm(logit)\n",
    "print(logit)\n",
    "print(p)\n",
    "#hist = np.zeros((3,))\n",
    "#for i in range(100):\n",
    "hist = obj(logit).numpy()\n",
    "print(hist)    \n",
    "#plt.hist(g)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "file = \"config.yaml\"\n",
    "with open(file, 'r') as file_descriptor:\n",
    "    data = yaml.load(file_descriptor, Loader=yaml.FullLoader)\n",
    "    \n",
    "print(type(data[\"CycleGan\"]['Generator']['filters']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
